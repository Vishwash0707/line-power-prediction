# -*- coding: utf-8 -*-
"""prediction_of_linepower.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-Y5FIw8r5YoVuJnVN4M0R78liQmtU76
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from keras.layers import Dense, Activation, BatchNormalization, Dropout
from keras import regularizers
from keras.optimizers import RMSprop, Adam, SGD

import matplotlib.pyplot as plt

# Load the dataset
dts = pd.read_excel('DATA SET IEEE.xlsx')
dts.head(10)

df1 = pd.DataFrame(dts)
x_column_indices = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22] + list(range(28, 42))

# Create the x DataFrame using iloc for index-based selection
x = df1.iloc[:, x_column_indices]

# Create the y Series using iloc to select the last column
y_column_indices = [49, 50, 51, 52, 53, 54, 55]
y = df1.iloc[:, y_column_indices]
print(x.shape, y.shape)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
print("Train Shape: {} {} \nTest Shape: {} {}".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))

from sklearn.preprocessing import StandardScaler
# input scaling
sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)
# output scaling
sc_y = StandardScaler()
y_train = sc_y.fit_transform(y_train)
y_test = sc_y.transform(y_test)

import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt

# Define the model building function
def model_build(n_activation, kernels, input_dim):
    model = tf.keras.models.Sequential()

    # Manually adding layers
    model.add(tf.keras.layers.Dense(28, kernel_initializer=kernels, activation=n_activation, input_dim=input_dim))
    model.add(tf.keras.layers.Dense(21, activation=n_activation, kernel_initializer=kernels))

    # Output layer for regression with a single node
    model.add(tf.keras.layers.Dense(7, activation='linear'))

    # Compile the model
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])

    return model

# Example usage
n_activation = 'relu'
kernels = 'normal'
input_dim = x_train.shape[1]  # assuming x_train is available

# Build and summarize the model
final_model = model_build(n_activation, kernels, input_dim)
final_model.summary()

# Train the model
history = final_model.fit(x_train, y_train, batch_size=32, validation_data=(x_test, y_test), epochs=30, verbose=2)

# Evaluate the model
train_loss, train_mae = final_model.evaluate(x_train, y_train, verbose=0)
test_loss, test_mae = final_model.evaluate(x_test, y_test, verbose=0)

# Save the results in a DataFrame
rf_results = pd.DataFrame([['ANN', train_mae, test_mae]], columns=['Method', 'MAE Score of Training Set', 'MAE Score of Test Set'])
print(rf_results)

# Access and plot the 'mean_absolute_error' from the 'history' dictionary of the 'History' object
plt.plot(history.history['mean_absolute_error'])
plt.plot(history.history['val_mean_absolute_error'])  # Plot validation MAE as well
plt.title('Mean Absolute Error')
plt.xlabel('Epochs')
plt.ylabel('Error')
plt.legend(['Train', 'Validation'])
plt.show()

230final_model.evaluate(x_train, y_train)

"""#**Random Forest**"""

from sklearn.ensemble import RandomForestRegressor
model_rf = RandomForestRegressor(n_estimators=10, random_state=30)
model_rf.fit(x_train, y_train)

y_pred_rf = model_rf.predict(x_test)

from sklearn.metrics import mean_squared_error, mean_absolute_error
mse_rf = mean_squared_error(y_test, y_pred_rf)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
print('Mean squared error using Random Forest: ', mse_rf)
print('Mean absolute error Using Random Forest: ', mae_rf)

"""#**Decision Tree**"""

from sklearn.tree import DecisionTreeRegressor
tree = DecisionTreeRegressor()
tree.fit(x_train, y_train)
y_pred_tree = tree.predict(x_test)
mse_dt = mean_squared_error(y_test, y_pred_tree)
mae_dt = mean_absolute_error(y_test, y_pred_tree)
print('Mean squared error using decision tree: ', mse_dt)
print('Mean absolute error using decision tree: ', mae_dt)

"""#**User Input Prediction**"""

# Function to scale user input
def scale_input(user_input, scaler):
    user_input_scaled = scaler.transform([user_input])
    return user_input_scaled

# Get user input
user_input = []
for i in range(x.shape[1]):
    value = float(input(f"Enter value for feature {i + 1}: "))
    user_input.append(value)

# Scale the user input
user_input_scaled = scale_input(user_input, sc_x)

# Predict using the deep learning model
user_prediction_dl = final_model.predict(user_input_scaled)
user_prediction_dl = sc_y.inverse_transform(user_prediction_dl)
print('Deep Learning Model Prediction:', user_prediction_dl)

# Predict using the Random Forest model
user_prediction_rf = model_rf.predict(user_input_scaled)
user_prediction_rf = sc_y.inverse_transform(user_prediction_rf)
print('Random Forest Model Prediction:', user_prediction_rf)

# Predict using the Decision Tree model
user_prediction_tree = tree.predict(user_input_scaled)
user_prediction_tree = sc_y.inverse_transform(user_prediction_tree)
print('Decision Tree Model Prediction:', user_prediction_tree)